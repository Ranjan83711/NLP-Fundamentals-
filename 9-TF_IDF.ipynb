{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c39afb85",
   "metadata": {},
   "source": [
    "Great ðŸ‘Œ now letâ€™s move from **Bag of Words (BoW)** and **N-grams** to something smarter: **TF and IDF**.\n",
    "\n",
    "---\n",
    "\n",
    "# ðŸ“Œ 1. Term Frequency (TF)\n",
    "\n",
    "ðŸ‘‰ **TF tells how often a word appears in a document.**\n",
    "\n",
    "$$\n",
    "TF(t, d) = \\frac{\\text{Number of times term } t \\text{ appears in document } d}{\\text{Total number of terms in document } d}\n",
    "$$\n",
    "\n",
    "* Example:\n",
    "  Document: `\"I love NLP and I love Python\"`\n",
    "\n",
    "  * Word `\"love\"` appears **2 times**\n",
    "  * Total words = 7\n",
    "\n",
    "  $$\n",
    "  TF(love) = \\frac{2}{7} = 0.285\n",
    "  $$\n",
    "\n",
    "---\n",
    "\n",
    "# ðŸ“Œ 2. Inverse Document Frequency (IDF)\n",
    "\n",
    "ðŸ‘‰ **IDF tells how unique or rare a word is across all documents.**\n",
    "\n",
    "$$\n",
    "IDF(t) = \\log \\left( \\frac{\\text{Total number of documents}}{\\text{Number of documents containing term } t} \\right)\n",
    "$$\n",
    "\n",
    "* Example: Suppose we have 10 documents:\n",
    "\n",
    "  * Word `\"love\"` appears in 2 documents\n",
    "  * Word `\"NLP\"` appears in 8 documents\n",
    "\n",
    "  $$\n",
    "  IDF(love) = \\log \\left(\\frac{10}{2}\\right) = \\log(5) \\approx 1.6\n",
    "  $$\n",
    "\n",
    "  $$\n",
    "  IDF(NLP) = \\log \\left(\\frac{10}{8}\\right) = \\log(1.25) \\approx 0.22\n",
    "  $$\n",
    "\n",
    "ðŸ“Œ Interpretation:\n",
    "\n",
    "* Common words (like `\"NLP\"`, `\"the\"`, `\"and\"`) â†’ **low IDF** (less important).\n",
    "* Rare words (like `\"love\"`) â†’ **high IDF** (more important).\n",
    "\n",
    "---\n",
    "\n",
    "# ðŸ“Œ 3. TF-IDF (Combined)\n",
    "\n",
    "ðŸ‘‰ **TF-IDF = TF Ã— IDF**\n",
    "\n",
    "* This balances word importance:\n",
    "\n",
    "  * High TF = appears frequently in a document\n",
    "  * High IDF = rare across many documents\n",
    "\n",
    "ðŸ“Œ Example with `\"love\"`:\n",
    "\n",
    "$$\n",
    "TF-IDF(love) = TF(love) \\times IDF(love) = 0.285 \\times 1.6 \\approx 0.456\n",
    "$$\n",
    "\n",
    "So `\"love\"` is more **important** in that document compared to `\"NLP\"` (which had low IDF).\n",
    "\n",
    "---\n",
    "\n",
    "# ðŸ“Œ Why TF-IDF is better than BoW?\n",
    "\n",
    "* BoW just counts words (so `\"the\"` and `\"NLP\"` may look equally important).\n",
    "* TF-IDF reduces weight for **common words** and increases weight for **rare but meaningful words**.\n",
    "\n",
    "---\n",
    "\n",
    "ðŸ‘‰ Do you want me to write a **full code example in Python** where we compute **TF-IDF with NLTK preprocessing + sklearnâ€™s `TfidfVectorizer`**? That way, you can see it in action with real numbers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e622e4",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
